{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification - Determine International Rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import math\n",
    "import re\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, multilabel_confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, LabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier, _fit_binary\n",
    "from itertools import cycle, product\n",
    "from sklearn.manifold import TSNE, MDS, Isomap\n",
    "import seaborn as sns\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "import hyperopt.pyll.stochastic\n",
    "import time\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:  (3563, 32)\n",
      "1.0    3236\n",
      "2.0     262\n",
      "3.0      65\n",
      "Name: International Reputation, dtype: int64\n",
      "n_classes:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Read original data\n",
    "sample_data = pd.read_csv('fifa19_features_reduced_data.csv', encoding='utf-8')\n",
    "\n",
    "# Separate internation rating result with rest\n",
    "y = sample_data['International Reputation']\n",
    "X = sample_data.drop('International Reputation', axis=1)\n",
    "print('X: ', X.shape)\n",
    "\n",
    "# Binarize the rating result\n",
    "# Rating score 5 records is only 6 / 18208, so it cannot be predicated with too little data,\n",
    "# we convert the score 5 and 4 to 3, so only choose rating scores 1, 2, 3 to classify.\n",
    "sample_data['International Reputation'].loc[sample_data['International Reputation'] == 5] = 3\n",
    "sample_data['International Reputation'].loc[sample_data['International Reputation'] == 4] = 3\n",
    "sample_data.hist(column='International Reputation')\n",
    "y_n = sample_data['International Reputation']\n",
    "\n",
    "print(sample_data['International Reputation'].value_counts())\n",
    "\n",
    "y = label_binarize(y, classes=[1, 2, 3])\n",
    "n_classes = y.shape[1]\n",
    "print('n_classes: ', n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (2375, 32) X_test:  (1188, 32)\n",
      "Rating Score value counts:  1\n",
      "1    2162\n",
      "0     213\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Rating Score value counts:  2\n",
      "0    2203\n",
      "1     172\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Rating Score value counts:  3\n",
      "0    2334\n",
      "1      41\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "X_n_train:  (2375, 32) y_n_ftest:  (1188, 32)\n"
     ]
    }
   ],
   "source": [
    "# Divide data into training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=1)\n",
    "print('X_train: ', X_train.shape, 'X_test: ', X_test.shape)\n",
    "\n",
    "#print(y_train)\n",
    "for i in range(n_classes):\n",
    "    print(\"Rating Score value counts: \", i + 1)\n",
    "    print(pd.value_counts(y_train[:, i]))\n",
    "    plt.hist(y_train[:, i], bins=3)\n",
    "    plt.show()\n",
    "    print(\" \")\n",
    "\n",
    "X_n_train,X_n_test,y_n_train,y_n_test = train_test_split(X,y_n,test_size=1/3,random_state=1)\n",
    "print('X_n_train: ', X_n_train.shape, 'y_n_ftest: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 1000/1000 [31:00<00:00,  1.86s/it, best loss: 0.07873616059456767]\n",
      "                                                                      \n",
      "activation                tanh      tanh      tanh      tanh      tanh\n",
      "alpha                  34.1672   52.6964   60.4381   36.1015   21.7589\n",
      "hidden_layer_sizes          40        12        39        25        44\n",
      "learning_rate       invscaling  constant  constant  constant  constant\n",
      "learning_rate_init    0.740528  0.952365  0.943256  0.936478  0.791316\n",
      "power_t               0.773628   0.95518  0.588183  0.943391  0.904474\n",
      "solver                   lbfgs     lbfgs     lbfgs     lbfgs     lbfgs\n",
      "best_score            0.921264  0.917896   0.91789   0.91789  0.917479\n"
     ]
    }
   ],
   "source": [
    "# Set up space dictionary with specified hyperparameters\n",
    "space = {'hidden_layer_sizes': hp.choice('hidden_layer_sizes', range(1,56)),\n",
    "         'activation': hp.choice('activation', ['logistic','tanh','relu', 'identity']),\n",
    "         'solver': hp.choice('solver', ['lbfgs','sgd','adam']),\n",
    "         'alpha': hp.uniform('alpha', 0.0001, 1000),\n",
    "         'learning_rate': hp.choice('learning_rate', ['constant', 'invscaling', 'adaptive']),\n",
    "         'learning_rate_init': hp.uniform('learning_rate_init', 0.001, 0.99),\n",
    "         'power_t': hp.uniform('power_t', 0.01, 0.99)}\n",
    "\n",
    "target_clf = [None] * 10\n",
    "target_clf_fitted = [None] * 10\n",
    "target_y_pred_proba = [None] * 10\n",
    "target_y_pred = [None] * 10\n",
    "\n",
    "# Set up objective function\n",
    "def objective(params):\n",
    "    params = {'hidden_layer_sizes': params['hidden_layer_sizes'],\n",
    "              'activation': params['activation'],\n",
    "              'solver': params['solver'],\n",
    "              'alpha': params['alpha'],\n",
    "              'learning_rate': params['learning_rate'],\n",
    "              'learning_rate_init': params['learning_rate_init'],\n",
    "              'power_t': params['power_t']}\n",
    "        \n",
    "    hyperopt_clf = MLPClassifier(max_iter=4000,\n",
    "                                 random_state=42,\n",
    "                                 warm_start=True,\n",
    "                                 early_stopping=True,\n",
    "                                 **params)\n",
    "\n",
    "    best_score = cross_val_score(estimator=hyperopt_clf,\n",
    "                                 X=X_train,\n",
    "                                 y=y_train,\n",
    "                                 cv=3,\n",
    "                                 n_jobs=4,\n",
    "                                 pre_dispatch=10).mean()\n",
    "    \n",
    "    loss = 1 - best_score\n",
    "    return {'best_score': best_score, 'loss': loss, 'status': STATUS_OK,'eval_time': time.time()}\n",
    "\n",
    "# Run the algorithm\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "           space=space,\n",
    "           max_evals=1000,\n",
    "           rstate=np.random.RandomState(42),\n",
    "           algo=tpe.suggest,\n",
    "           trials=trials)\n",
    "    \n",
    "best_score = [None] * len(trials.trials)\n",
    "best_score[0] = trials.results[0].get('best_score')\n",
    "\n",
    "searched_params_df = pd.DataFrame(trials.trials[0].get('misc').get('vals').values())\n",
    "searched_params_df = searched_params_df.transpose()\n",
    "\n",
    "for i in list(range(1, len(trials.trials))):\n",
    "    new_df = pd.DataFrame(trials.trials[i].get('misc').get('vals').values())\n",
    "    searched_params_df = searched_params_df.append(new_df.transpose())\n",
    "    best_score[i] = trials.results[i].get('best_score')\n",
    "\n",
    "searched_params_df = searched_params_df.rename(columns={0: 'activation', 1: 'alpha', 2: 'hidden_layer_sizes', \n",
    "                                                            3: 'learning_rate', 4: 'learning_rate_init', \n",
    "                                                            5: 'power_t', 6: 'solver'})\n",
    "    \n",
    "blankIndex = [''] * len(searched_params_df)\n",
    "searched_params_df.index = blankIndex\n",
    "    \n",
    "i = ['activation', 'learning_rate', 'solver']\n",
    "j = ['logistic', 'constant', 'lbfgs']\n",
    "k = ['tanh', 'invscaling', 'sgd']\n",
    "l = ['relu', 'adaptive', 'adam']\n",
    "m = ['identity']\n",
    "\n",
    "for (i, j, k, l) in zip(i, j, k, l):\n",
    "    searched_params_df[i] = searched_params_df[i].replace({0: j, 1: k, 2: l, 3: m})\n",
    "\n",
    "searched_params_df['best_score'] = best_score\n",
    "\n",
    "searched_params_df_sorted = searched_params_df.sort_values(by='best_score', \n",
    "                                                               axis=0, \n",
    "                                                               ascending=False)\n",
    "    \n",
    "searched_params_df_sorted = searched_params_df_sorted[searched_params_df_sorted.hidden_layer_sizes != 0]\n",
    "\n",
    "print(searched_params_df_sorted.head(5).transpose())\n",
    "    \n",
    "# Learn to predict each class against the other\n",
    "        \n",
    "for i in range(5):\n",
    "    target_clf[i] = MLPClassifier(max_iter=4000,\n",
    "                                            random_state=42,\n",
    "                                            warm_start=True,\n",
    "                                            early_stopping=True,\n",
    "                                            activation=searched_params_df_sorted.values[i][0],\n",
    "                                            alpha=searched_params_df_sorted.values[i][1],\n",
    "                                            hidden_layer_sizes=int(searched_params_df_sorted.values[i][2]),\n",
    "                                            learning_rate=searched_params_df_sorted.values[i][3],\n",
    "                                            learning_rate_init=searched_params_df_sorted.values[i][4],\n",
    "                                            power_t=searched_params_df_sorted.values[i][5],\n",
    "                                            solver=searched_params_df_sorted.values[i][6])\n",
    "    \n",
    "\n",
    "for i in range(5):\n",
    "    target_clf_fitted[i] = target_clf[i].fit(X_train, y_train)\n",
    "    target_y_pred_proba[i] = target_clf[i].predict_proba(X_test)\n",
    "    target_y_pred[i] = target_clf[i].predict(X_test)\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'hidden_layer_sizes': list(product(range(1,56), range(1,56)))}\n",
    "    \n",
    "# Create a random search object\n",
    "ran_clf = RandomizedSearchCV(estimator = MLPClassifier(max_iter=4000,\n",
    "                                                           random_state=42,\n",
    "                                                           warm_start=True,\n",
    "                                                           early_stopping=True,\n",
    "                                                           activation=searched_params_df_sorted.values[0][0],\n",
    "                                                           alpha=searched_params_df_sorted.values[0][1],\n",
    "                                                           learning_rate=searched_params_df_sorted.values[0][3],\n",
    "                                                           learning_rate_init=searched_params_df_sorted.values[0][4],\n",
    "                                                           power_t=searched_params_df_sorted.values[0][5],\n",
    "                                                           solver=searched_params_df_sorted.values[0][6]),\n",
    "                                 param_distributions=param_grid,\n",
    "                                 n_iter=465,\n",
    "                                 n_jobs=4,\n",
    "                                 pre_dispatch=100,\n",
    "                                 cv=3,\n",
    "                                 random_state=42)\n",
    "\n",
    "ran_clf_fitted = ran_clf.fit(X_train, y_train)\n",
    "\n",
    "#Configuration of Layer 1 & 2\n",
    "mean_test_score = list(ran_clf_fitted.cv_results_.get('mean_test_score'))\n",
    "hidden_layers = list(ran_clf_fitted.cv_results_.get('param_hidden_layer_sizes'))\n",
    "\n",
    "best_hidden_layers_df = pd.DataFrame({'Hidden Layers': hidden_layers, 'Mean Test Score': mean_test_score})\n",
    "\n",
    "blankIndex = [''] * len(best_hidden_layers_df)\n",
    "best_hidden_layers_df.index = blankIndex\n",
    "\n",
    "# Print out the best configuration of hidden layers\n",
    "best_hidden_layers_df_sorted = best_hidden_layers_df.sort_values(by='Mean Test Score', \n",
    "                                                                     axis=0, \n",
    "                                                                     ascending=False)\n",
    "\n",
    "print(best_hidden_layers_df_sorted.head(5).transpose())\n",
    "\n",
    "for i in range(5, 10):\n",
    "      target_clf[i] = MLPClassifier(max_iter=4000,\n",
    "                                            random_state=42,\n",
    "                                            warm_start=True,\n",
    "                                            early_stopping=True,\n",
    "                                            activation=searched_params_df_sorted.values[0][0],\n",
    "                                            alpha=searched_params_df_sorted.values[0][1],\n",
    "                                            hidden_layer_sizes=best_hidden_layers_df_sorted['Hidden Layers'].values[i-6],\n",
    "                                            learning_rate=searched_params_df_sorted.values[0][3],\n",
    "                                            learning_rate_init=searched_params_df_sorted.values[0][4],\n",
    "                                            power_t=searched_params_df_sorted.values[0][5],\n",
    "                                            solver=searched_params_df_sorted.values[0][6])\n",
    "    \n",
    "for i in range(5, 10):\n",
    "    target_clf_fitted[i] = target_clf[i].fit(X_train, y_train)\n",
    "    target_y_pred_proba[i] = target_clf[i].predict_proba(X_test)\n",
    "    target_y_pred[i] = target_clf[i].predict(X_test)\n",
    "\n",
    "sns.set(rc={'figure.figsize': (35,40), 'legend.fontsize': 25, 'xtick.labelsize': 20, 'ytick.labelsize': 20, \n",
    "                'lines.markersize': 10, 'axes.labelsize': 0, 'axes.titlesize': 20})\n",
    "\n",
    "fig, ax = plt.subplots(7,1)\n",
    "\n",
    "j = ['Activation Function for the Hidden Layer', 'L2 Penalty', 'Number of Neurons', \n",
    "         'Learning Rate Schedule for Weight Updates', 'Initial Learning Rate', 'Exponent for Inverse Scaling Learning Rate',\n",
    "         'Solver for Weight Optimization']\n",
    "k = ['activation', 'alpha', 'hidden_layer_sizes', 'learning_rate', 'learning_rate_init', 'power_t', 'solver']\n",
    "    \n",
    "for (i, j, k) in zip(range(7), j, k):\n",
    "    \n",
    "    ax[i].set_title('Searched Parameters of the {}'.format(j))\n",
    "    sns.scatterplot(x=list(range(0, len(trials.trials))), \n",
    "                        y=searched_params_df[k].values, \n",
    "                        ax=ax[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1stBest_1Layer----------\n",
      "\n",
      "[[[  80   34]\n",
      "  [  24 1050]]\n",
      "\n",
      " [[1069   29]\n",
      "  [  51   39]]\n",
      "\n",
      " [[1163    4]\n",
      "  [  21    0]]\n",
      "\n",
      " [[1183    2]\n",
      "  [   2    1]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1074\n",
      "           1       0.57      0.43      0.49        90\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.33      0.33      0.33         3\n",
      "\n",
      "   micro avg       0.94      0.92      0.93      1188\n",
      "   macro avg       0.47      0.44      0.45      1188\n",
      "weighted avg       0.92      0.92      0.92      1188\n",
      " samples avg       0.92      0.92      0.92      1188\n",
      "\n",
      "2ndBest_1Layer----------\n",
      "\n",
      "[[[  77   37]\n",
      "  [  25 1049]]\n",
      "\n",
      " [[1073   25]\n",
      "  [  52   38]]\n",
      "\n",
      " [[1166    1]\n",
      "  [  21    0]]\n",
      "\n",
      " [[1184    1]\n",
      "  [   2    1]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1074\n",
      "           1       0.60      0.42      0.50        90\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.50      0.33      0.40         3\n",
      "\n",
      "   micro avg       0.94      0.92      0.93      1188\n",
      "   macro avg       0.52      0.43      0.47      1188\n",
      "weighted avg       0.92      0.92      0.92      1188\n",
      " samples avg       0.92      0.92      0.92      1188\n",
      "\n",
      "3rdBest_1Layer----------\n",
      "\n",
      "[[[  80   34]\n",
      "  [  27 1047]]\n",
      "\n",
      " [[1071   27]\n",
      "  [  54   36]]\n",
      "\n",
      " [[1163    4]\n",
      "  [  21    0]]\n",
      "\n",
      " [[1183    2]\n",
      "  [   2    1]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1074\n",
      "           1       0.57      0.40      0.47        90\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.33      0.33      0.33         3\n",
      "\n",
      "   micro avg       0.94      0.91      0.93      1188\n",
      "   macro avg       0.47      0.43      0.44      1188\n",
      "weighted avg       0.92      0.91      0.91      1188\n",
      " samples avg       0.91      0.91      0.91      1188\n",
      "\n",
      "4thBest_1Layer----------\n",
      "\n",
      "[[[  76   38]\n",
      "  [  25 1049]]\n",
      "\n",
      " [[1069   29]\n",
      "  [  56   34]]\n",
      "\n",
      " [[1163    4]\n",
      "  [  21    0]]\n",
      "\n",
      " [[1183    2]\n",
      "  [   2    1]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1074\n",
      "           1       0.54      0.38      0.44        90\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.33      0.33      0.33         3\n",
      "\n",
      "   micro avg       0.94      0.91      0.92      1188\n",
      "   macro avg       0.46      0.42      0.44      1188\n",
      "weighted avg       0.91      0.91      0.91      1188\n",
      " samples avg       0.91      0.91      0.91      1188\n",
      "\n",
      "5thBest_1Layer----------\n",
      "\n",
      "[[[  79   35]\n",
      "  [  23 1051]]\n",
      "\n",
      " [[1074   24]\n",
      "  [  53   37]]\n",
      "\n",
      " [[1167    0]\n",
      "  [  21    0]]\n",
      "\n",
      " [[1184    1]\n",
      "  [   2    1]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1074\n",
      "           1       0.61      0.41      0.49        90\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.50      0.33      0.40         3\n",
      "\n",
      "   micro avg       0.95      0.92      0.93      1188\n",
      "   macro avg       0.52      0.43      0.47      1188\n",
      "weighted avg       0.92      0.92      0.92      1188\n",
      " samples avg       0.92      0.92      0.92      1188\n",
      "\n",
      "1stBest_2Layers----------\n",
      "\n",
      "[[[ 103   11]\n",
      "  [ 892  182]]\n",
      "\n",
      " [[1098    0]\n",
      "  [  90    0]]\n",
      "\n",
      " [[1167    0]\n",
      "  [  21    0]]\n",
      "\n",
      " [[1185    0]\n",
      "  [   3    0]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.17      0.29      1074\n",
      "           1       0.00      0.00      0.00        90\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.00      0.00      0.00         3\n",
      "\n",
      "   micro avg       0.94      0.15      0.26      1188\n",
      "   macro avg       0.24      0.04      0.07      1188\n",
      "weighted avg       0.85      0.15      0.26      1188\n",
      " samples avg       0.15      0.15      0.15      1188\n",
      "\n",
      "2ndBest_2Layers----------\n",
      "\n",
      "[[[  78   36]\n",
      "  [  30 1044]]\n",
      "\n",
      " [[1063   35]\n",
      "  [  50   40]]\n",
      "\n",
      " [[1164    3]\n",
      "  [  18    3]]\n",
      "\n",
      " [[1184    1]\n",
      "  [   2    1]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1074\n",
      "           1       0.53      0.44      0.48        90\n",
      "           2       0.50      0.14      0.22        21\n",
      "           3       0.50      0.33      0.40         3\n",
      "\n",
      "   micro avg       0.94      0.92      0.93      1188\n",
      "   macro avg       0.62      0.47      0.52      1188\n",
      "weighted avg       0.92      0.92      0.92      1188\n",
      " samples avg       0.92      0.92      0.92      1188\n",
      "\n",
      "3rdBest_2Layers----------\n",
      "\n",
      "[[[  80   34]\n",
      "  [  25 1049]]\n",
      "\n",
      " [[1070   28]\n",
      "  [  40   50]]\n",
      "\n",
      " [[1167    0]\n",
      "  [  21    0]]\n",
      "\n",
      " [[1184    1]\n",
      "  [   2    1]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1074\n",
      "           1       0.64      0.56      0.60        90\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.50      0.33      0.40         3\n",
      "\n",
      "   micro avg       0.95      0.93      0.94      1188\n",
      "   macro avg       0.53      0.47      0.49      1188\n",
      "weighted avg       0.93      0.93      0.93      1188\n",
      " samples avg       0.93      0.93      0.93      1188\n",
      "\n",
      "4thBest_2Layers----------\n",
      "\n",
      "[[[  83   31]\n",
      "  [  33 1041]]\n",
      "\n",
      " [[1057   41]\n",
      "  [  38   52]]\n",
      "\n",
      " [[1167    0]\n",
      "  [  21    0]]\n",
      "\n",
      " [[1185    0]\n",
      "  [   2    1]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1074\n",
      "           1       0.56      0.58      0.57        90\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       1.00      0.33      0.50         3\n",
      "\n",
      "   micro avg       0.94      0.92      0.93      1188\n",
      "   macro avg       0.63      0.47      0.51      1188\n",
      "weighted avg       0.92      0.92      0.92      1188\n",
      " samples avg       0.92      0.92      0.92      1188\n",
      "\n",
      "5thBest_2Layers----------\n",
      "\n",
      "[[[  80   34]\n",
      "  [  22 1052]]\n",
      "\n",
      " [[1070   28]\n",
      "  [  42   48]]\n",
      "\n",
      " [[1167    0]\n",
      "  [  21    0]]\n",
      "\n",
      " [[1184    1]\n",
      "  [   2    1]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1074\n",
      "           1       0.63      0.53      0.58        90\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.50      0.33      0.40         3\n",
      "\n",
      "   micro avg       0.95      0.93      0.94      1188\n",
      "   macro avg       0.53      0.46      0.49      1188\n",
      "weighted avg       0.92      0.93      0.93      1188\n",
      " samples avg       0.93      0.93      0.93      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print classification report\n",
    "\n",
    "i = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "j = ['1stBest_1Layer', '2ndBest_1Layer', '3rdBest_1Layer', '4thBest_1Layer', '5thBest_1Layer', \n",
    "     '1stBest_2Layers', '2ndBest_2Layers', '3rdBest_2Layers', '4thBest_2Layers', '5thBest_2Layers']\n",
    "\n",
    "for (i, j) in zip(i, j):\n",
    "    print('{}----------'.format(j))\n",
    "    print()\n",
    "    print(multilabel_confusion_matrix(y_true=y_test, \n",
    "                                      y_pred=target_y_pred[i]))\n",
    "    print(classification_report(y_true=y_test, \n",
    "                                y_pred=target_y_pred[i],\n",
    "                                digits=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MLP estimator: MLPClassifier(activation='relu', alpha=21.634787039154073, batch_size='auto',\n",
      "              beta_1=0.9, beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
      "              hidden_layer_sizes=38, learning_rate='adaptive',\n",
      "              learning_rate_init=0.16146925676060042, max_iter=4000,\n",
      "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
      "              power_t=0.399917755259629, random_state=42, shuffle=True,\n",
      "              solver='lbfgs', tol=0.0001, validation_fraction=0.1,\n",
      "              verbose=False, warm_start=True)\n",
      "\n",
      "Best results\n",
      "[[[  80   34]\n",
      "  [  24 1050]]\n",
      "\n",
      " [[1069   29]\n",
      "  [  51   39]]\n",
      "\n",
      " [[1163    4]\n",
      "  [  21    0]]\n",
      "\n",
      " [[1183    2]\n",
      "  [   2    1]]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97      1074\n",
      "           1       0.57      0.43      0.49        90\n",
      "           2       0.00      0.00      0.00        21\n",
      "           3       0.33      0.33      0.33         3\n",
      "\n",
      "   micro avg       0.94      0.92      0.93      1188\n",
      "   macro avg       0.47      0.44      0.45      1188\n",
      "weighted avg       0.92      0.92      0.92      1188\n",
      " samples avg       0.92      0.92      0.92      1188\n",
      "\n",
      "\n",
      "           Variable  Feature_Importances\n",
      "4              Wage             0.011776\n",
      "0               Age             0.010842\n",
      "35        ShotPower             0.006431\n",
      "26            Curve             0.004966\n",
      "1           Overall             0.004680\n",
      "50       GKHandling             0.004175\n",
      "25        Dribbling             0.004074\n",
      "37          Stamina             0.004024\n",
      "38         Strength             0.003333\n",
      "9                ST             0.003266\n",
      "40       Aggression             0.002971\n",
      "29      BallControl             0.002938\n",
      "10               RS             0.002921\n",
      "6       Skill Moves             0.002508\n",
      "21        Finishing             0.002433\n",
      "7            Height             0.002340\n",
      "46          Marking             0.002306\n",
      "34          Balance             0.002281\n",
      "49         GKDiving             0.002020\n",
      "24          Volleys             0.001911\n",
      "48    SlidingTackle             0.001776\n",
      "11               RF             0.001625\n",
      "12               RW             0.001549\n",
      "8            Weight             0.001473\n",
      "32          Agility             0.001347\n",
      "22  HeadingAccuracy             0.001288\n",
      "45        Composure             0.001136\n",
      "3             Value             0.000892\n",
      "52    GKPositioning             0.000816\n",
      "31      SprintSpeed             0.000783\n",
      "15               RM             0.000606\n",
      "30     Acceleration             0.000572\n",
      "28      LongPassing             0.000295\n",
      "39        LongShots             0.000269\n",
      "41    Interceptions             0.000219\n",
      "20         Crossing             0.000126\n",
      "54      Attack_rate             0.000025\n",
      "51        GKKicking            -0.000177\n",
      "17              RWB            -0.000253\n",
      "14              RCM            -0.000269\n",
      "47   StandingTackle            -0.000328\n",
      "2         Potential            -0.000354\n",
      "19               RB            -0.000438\n",
      "42      Positioning            -0.000589\n",
      "5           Special            -0.000614\n",
      "16              RDM            -0.000690\n",
      "33        Reactions            -0.000825\n",
      "53       GKReflexes            -0.000951\n",
      "18              RCB            -0.001145\n",
      "43           Vision            -0.001279\n",
      "13              RAM            -0.001675\n",
      "36          Jumping            -0.002130\n",
      "55     Defense_rate            -0.002290\n",
      "27       FKAccuracy            -0.002710\n",
      "23     ShortPassing            -0.002795\n",
      "44        Penalties            -0.002795\n"
     ]
    }
   ],
   "source": [
    "# Computing feature importance\n",
    "print('Best MLP estimator: {}'.format(target_clf[0]))\n",
    "print()\n",
    "print('Best results')\n",
    "print(multilabel_confusion_matrix(y_true=y_test, \n",
    "                                  y_pred=target_y_pred[0]))\n",
    "print(classification_report(y_true=y_test, \n",
    "                            y_pred=target_y_pred[0],\n",
    "                            digits=2))\n",
    "\n",
    "perm = PermutationImportance(estimator=target_clf[0],\n",
    "                             n_iter=100,\n",
    "                             random_state=42).fit(X_test, y_test)\n",
    "\n",
    "# Create a dataframe of the variables and feature importances\n",
    "feature_importances_df = pd.DataFrame({'Variable': X.columns, 'Feature_Importances': perm.feature_importances_})\n",
    "\n",
    "# Print out the top 3 positive variables\n",
    "feature_importances_df_sorted = feature_importances_df.sort_values(by='Feature_Importances', \n",
    "                                                                   axis=0, \n",
    "                                                                   ascending=False)\n",
    "print()\n",
    "print(feature_importances_df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
